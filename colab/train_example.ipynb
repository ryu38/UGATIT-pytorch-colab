{"cells":[{"cell_type":"markdown","source":["## Prepare for training"],"metadata":{"id":"c6r44WOrymrU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hVw_oy65ShJ"},"outputs":[],"source":["# check allocated gpu\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h0eeJjp4BiPf"},"outputs":[],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mVcYdTDO5SJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfDabiDAo80O"},"outputs":[],"source":["base_dir = 'drive/MyDrive/' + <your project dir>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9ATcB6R2j3j"},"outputs":[],"source":["!git clone https://github.com/ryu38/UGATIT-pytorch-colab.git\n","!mv UGATIT-pytorch-colab ugatit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWSeoJtzZ6-4"},"outputs":[],"source":["from ugatit.models.discriminator import Discriminator\n","from ugatit.models.generator import Generator, RhoClipper"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_7ZDtIMU_ag"},"outputs":[],"source":["import torch\n","print(torch.__version__)\n","from torch import nn\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import transforms\n","import torch.utils.data as data\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import numpy as np\n","\n","from PIL import Image\n","import pathlib\n","import random\n","import IPython.display as display\n","import time\n","import datetime\n","import os\n","import itertools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UptnWIkWDQIB"},"outputs":[],"source":["CHANNELS = 3\n","IMG_SIZE = 256\n","BATCH_SIZE = 1"]},{"cell_type":"markdown","source":["## Import datasets"],"metadata":{"id":"VA8LOqUl3VDl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgYQ9DagEcuA"},"outputs":[],"source":["dataset_dir = 'drive/MyDrive/' + <your dataset dir>\n","\n","dataset_name_a = <dataset A>\n","dataset_name_b = <dataset B>\n","\n","!mkdir dataset\n","!cp $dataset_dir/{dataset_name_a}.zip {dataset_name_a}.zip\n","!unzip {dataset_name_a}.zip -d dataset/{dataset_name_a}\n","!cp $dataset_dir/{dataset_name_b}.zip {dataset_name_b}.zip\n","!unzip {dataset_name_b}.zip -d dataset/{dataset_name_b}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5fdgeYcJ-yh"},"outputs":[],"source":["for img_group in ['trainA', 'trainB']:\n","    os.system(f'mkdir dataset/{img_group}')\n","\n","!mv -T dataset/{dataset_name_a} dataset/trainA\n","!mv -T dataset/{dataset_name_b} dataset/trainB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFdOX_8Kzi2G"},"outputs":[],"source":["dataset_path = pathlib.Path('dataset/')\n","\n","for img_group, var_name in zip(\n","    ['trainA', 'trainB'], \n","    ['train_a_paths', 'train_b_paths']\n","):\n","    img_paths = []\n","    for filetype in ['jpg', 'png']:\n","        img_paths.extend([str(path) for path in list(dataset_path.joinpath(img_group).glob(f'**/*.{filetype}'))])\n","    globals()[var_name] = img_paths\n","del img_paths\n","del dataset_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwGhZpcx0BNU"},"outputs":[],"source":["for n in range(3):\n","    img_path = random.choice(train_a_paths)\n","    # img_path = random.choice(train_b_paths)\n","    display.display(display.Image(img_path))\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tz5Tc9ecXyk2"},"outputs":[],"source":["print(len(train_a_paths), len(train_b_paths))"]},{"cell_type":"markdown","source":["## Preprocess training data"],"metadata":{"id":"_E7HnIHf6-4F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJhy_N75PkHI"},"outputs":[],"source":["class ImageModification():\n","    def __init__(self, resize_pixel, min_scale=0.9, flip_p=0.5):\n","        self.resize_crop = transforms.RandomResizedCrop(resize_pixel, scale=(min_scale, 1.0), ratio=(1.0, 1.0))\n","        self.flip = transforms.RandomHorizontalFlip(p=flip_p)\n","        self.color_jitter = transforms.ColorJitter(brightness=0.3, saturation=0.5, contrast=0.3)\n","        self.data_arrange = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n","        ])\n","\n","    def __call__(self,img):\n","        img = self.resize_crop(img)\n","        img = self.flip(img)\n","        img = self.color_jitter(img)\n","        # convert to tensor\n","        img = self.data_arrange(img)\n","        return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MD-9_1XG4Bk3"},"outputs":[],"source":["class GANDataset(data.Dataset):\n","\tdef __init__(self,file_list,transform):\n","\t\tself.file_list = file_list\n","\t\tself.transform = transform\n","        \n","\tdef __len__(self):\n","\t\treturn len(self.file_list)\n","  \n","\tdef __getitem__(self,index):\n","\t\timg_path = self.file_list[index]\n","\t\timg = Image.open(img_path)\n","\t\timg = img.convert('RGB')\n","\t\timg_transformed = self.transform(img)\n","\t\treturn img_transformed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkwm0oqT3vhT"},"outputs":[],"source":["transformer_a = ImageModification(resize_pixel=256, min_scale=0.7)\n","transformer_b = ImageModification(resize_pixel=256, min_scale=0.9)\n","\n","train_ds_a = GANDataset(file_list=train_a_paths, transform=transformer_a)\n","train_ds_b = GANDataset(file_list=train_b_paths, transform=transformer_b)\n","\n","train_a = torch.utils.data.DataLoader(train_ds_a, batch_size=BATCH_SIZE, shuffle=True)\n","train_b = torch.utils.data.DataLoader(train_ds_b, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miCXDV559VsY"},"outputs":[],"source":["sample = next(iter(train_a)).permute(0, 2, 3, 1)[0]\n","# sample = next(iter(train_b)).permute(0, 2, 3, 1)[0]\n","plt.figure()\n","plt.imshow(sample * 0.5 + 0.5)"]},{"cell_type":"markdown","source":["## Create or load ML models"],"metadata":{"id":"_WWJhyR8Y_3Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9tGAwqwub72o"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\",device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbAwSkk2DycA"},"outputs":[],"source":["g_a2b = Generator(n_blocks=8, light=True).to(device)\n","g_b2a = Generator(n_blocks=8, light=True).to(device)\n","d_ga = Discriminator(n_layers=7).to(device)\n","d_gb = Discriminator(n_layers=7).to(device)\n","d_la = Discriminator(n_layers=5).to(device)\n","d_lb = Discriminator(n_layers=5).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJXBBQp_cJWs"},"outputs":[],"source":["# If you create new model (not needed for loading pre-trained models)\n","\n","def weights_init(m):\n","\tclassname = m.__class__.__name__\n","\tif classname.find('Conv2d') != -1:\n","\t\tnn.init.normal_(m.weight.data, 0.0, 0.02)\n","\telif classname.find('ConvTranspose2d') != -1:\n","\t\tnn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","for model in [g_a2b, g_b2a, d_ga, d_gb, d_la, d_lb]:\n","    model.apply(weights_init)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lMzspg4DV0a"},"outputs":[],"source":["# If you load pre-trained model (not needed for creating new models)\n","\n","load_models_dirname = 'saved_models/' + <pre-trained models dirname>\n","load_models_filename = <pre-trained models filename> # ex. epoch-30.pt\n","\n","!mkdir trained_models\n","!cp {base_dir}/{load_models_dirname}/{load_models_filename} trained_models/{load_models_filename}\n","!ls trained_models/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_pqJMZqG_6N"},"outputs":[],"source":["# If you load pre-trained model (not needed for creating new models)\n","\n","ckpt = torch.load(os.path.join('trained_models', load_models_filename))\n","for model_name in ['g_a2b', 'g_b2a', 'd_ga', 'd_gb', 'd_la', 'd_lb']:\n","    globals()[model_name].load_state_dict(ckpt[model_name])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFi6a-rm2Iur"},"outputs":[],"source":["!pip install torchinfo\n","\n","from torchinfo import summary\n","\n","summary(\n","    g_a2b,\n","    input_size=(1, 3, 256, 256),\n","    col_names=[\"output_size\", \"num_params\"],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2EccHOaNH04"},"outputs":[],"source":["@torch.no_grad()\n","def generate_images(generator, source):\n","    num_sample = len(source)\n","    fake, _, _ = generator(source)\n","\n","    plt.figure(figsize=(10, 5 * num_sample))\n","    display_list = [source, fake]\n","    titles = ['input', 'fake']\n","\n","    for i, img_batch in enumerate(display_list):\n","        img_batch = img_batch.cpu().permute(0, 2, 3, 1)\n","        for j, img in enumerate(img_batch):\n","            plt.subplot(num_sample, 2, 2*j + 1 + i)\n","            plt.title(titles[i] + '_' + str(j))\n","            plt.imshow(img * 0.5 + 0.5)\n","            plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsBYzPWWRur_"},"outputs":[],"source":["def make_sample(img_paths, sample_num, transformer):\n","    sample_ds = GANDataset(file_list=img_paths, transform=transformer)\n","    samples = torch.utils.data.DataLoader(sample_ds, batch_size=sample_num, shuffle=True)\n","    return next(iter(samples))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"li6I-IK4YhA5"},"outputs":[],"source":["sample_a = make_sample(train_a_paths, 3, transformer_a).to(device)\n","sample_b = make_sample(train_b_paths, 3, transformer_b).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hAaRYQbPMF8"},"outputs":[],"source":["generate_images(g_a2b, sample_a)\n","generate_images(g_b2a, sample_b)"]},{"cell_type":"markdown","source":["## define loss and optimizer"],"metadata":{"id":"kboM-7K7oMdR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I2iJGA9SeAZ"},"outputs":[],"source":["mse_loss = nn.MSELoss().to(device)\n","l1_loss = nn.L1Loss().to(device)\n","bce_loss = nn.BCEWithLogitsLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPMS6s3nBIKs"},"outputs":[],"source":["def d_ad_loss(real_logit, fake_logit):\n","    return mse_loss(real_logit, torch.ones_like(real_logit).to(device)) + mse_loss(fake_logit, torch.zeros_like(fake_logit).to(device))\n","\n","def g_ad_loss(fake_logit):\n","    return mse_loss(fake_logit, torch.ones_like(fake_logit).to(device))\n","\n","def g_cycle_loss(fake_cycled_img, real_img):\n","    return l1_loss(fake_cycled_img, real_img)\n","\n","def g_identify_loss(fake_non_source_img, real_img):\n","    return l1_loss(fake_non_source_img, real_img)\n","\n","def g_cam_loss(source_cam, non_source_cam):\n","    return bce_loss(source_cam, torch.ones_like(source_cam).to(device)) + bce_loss(non_source_cam, torch.zeros_like(non_source_cam).to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4970fcnqrNQO"},"outputs":[],"source":["adam_lr = 0.0001\n","adam_b1 = 0.5\n","adam_b2 = 0.999\n","\n","opt_g = torch.optim.Adam(\n","    itertools.chain(\n","        g_a2b.parameters(),\n","        g_b2a.parameters()\n","    ),\n","    lr=adam_lr,\n","    betas=(adam_b1, adam_b2)\n",")\n","\n","opt_d = torch.optim.Adam(\n","    itertools.chain(\n","        d_ga.parameters(),\n","        d_gb.parameters(),\n","        d_la.parameters(),\n","        d_lb.parameters()\n","    ),\n","    lr=adam_lr,\n","    betas=(adam_b1, adam_b2)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTzQ9lXL2xCB"},"outputs":[],"source":["# If you load pre-trained model (not needed for creating new models)\n","\n","opt_g.load_state_dict(ckpt['opt_g'])\n","opt_d.load_state_dict(ckpt['opt_d'])"]},{"cell_type":"code","source":["# check learing rate\n","\n","opt_g.param_groups[0]['lr']\n","# opt_d.param_groups[0]['lr']"],"metadata":{"id":"xkjAHi49rNAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBOdEes2i8YD"},"outputs":[],"source":["rho_clipper = RhoClipper(0,1)\n","\n","def train_step(real_a, real_b):\n","\n","    # discriminator train\n","    opt_d.zero_grad()\n","\n","    x_ab, _, _ = g_a2b(real_a)\n","    x_ba, _, _ = g_b2a(real_b)\n","\n","    real_ga_logit, real_ga_cam, _ = d_ga(real_a)\n","    real_la_logit, real_la_cam, _ = d_la(real_a)\n","    real_gb_logit, real_gb_cam, _ = d_gb(real_b)\n","    real_lb_logit, real_lb_cam, _ = d_lb(real_b)\n","\n","    fake_ga_logit, fake_ga_cam, _ = d_ga(x_ba)\n","    fake_la_logit, fake_la_cam, _ = d_la(x_ba)\n","    fake_gb_logit, fake_gb_cam, _ = d_gb(x_ab)\n","    fake_lb_logit, fake_lb_cam, _ = d_lb(x_ab)\n","\n","    # calc loss\n","    d_ad_loss_ga = d_ad_loss(real_ga_logit, fake_ga_logit)\n","    d_ad_loss_la = d_ad_loss(real_la_logit, fake_la_logit)\n","    d_ad_loss_gb = d_ad_loss(real_gb_logit, fake_gb_logit)\n","    d_ad_loss_lb = d_ad_loss(real_lb_logit, fake_lb_logit)\n","\n","    d_ad_loss_ga_cam = d_ad_loss(real_ga_cam, fake_ga_cam)\n","    d_ad_loss_la_cam = d_ad_loss(real_la_cam, fake_la_cam)\n","    d_ad_loss_gb_cam = d_ad_loss(real_gb_cam, fake_gb_cam)\n","    d_ad_loss_lb_cam = d_ad_loss(real_lb_cam, fake_lb_cam)\n","\n","    d_ga_loss = d_ad_loss_ga + d_ad_loss_ga_cam\n","    d_la_loss =  d_ad_loss_la + d_ad_loss_la_cam\n","    d_gb_loss = d_ad_loss_gb + d_ad_loss_gb_cam\n","    d_lb_loss =  d_ad_loss_lb + d_ad_loss_lb_cam\n","\n","    d_loss = d_ga_loss + d_la_loss + d_gb_loss + d_lb_loss\n","\n","    d_loss.backward()\n","\n","    opt_d.step()\n","\n","    # generator train\n","    opt_g.zero_grad()\n","\n","    x_ab, x_ab_cam, _ = g_a2b(real_a)\n","    x_ba, x_ba_cam, _ = g_b2a(real_b)\n","\n","    x_aba, _, _ = g_b2a(x_ab)\n","    x_bab, _, _ = g_a2b(x_ba)\n","\n","    x_aa, x_aa_cam, _ = g_b2a(real_a)\n","    x_bb, x_bb_cam, _ = g_a2b(real_b)\n","\n","    fake_ga_logit, fake_ga_cam, _ = d_ga(x_ba)\n","    fake_la_logit, fake_la_cam, _ = d_la(x_ba)\n","    fake_gb_logit, fake_gb_cam, _ = d_gb(x_ab)\n","    fake_lb_logit, fake_lb_cam, _ = d_lb(x_ab)\n","\n","    # calc loss\n","    g_ad_loss_ga = g_ad_loss(fake_ga_logit) #b2a\n","    g_ad_loss_la = g_ad_loss(fake_la_logit) #b2a\n","    g_ad_loss_gb = g_ad_loss(fake_gb_logit) #a2b\n","    g_ad_loss_lb = g_ad_loss(fake_lb_logit) #a2b\n","    g_ad_loss_total = g_ad_loss_ga + g_ad_loss_la + g_ad_loss_gb + g_ad_loss_lb\n","\n","    g_ad_loss_ga_cam = g_ad_loss(fake_ga_cam) #b2a\n","    g_ad_loss_la_cam = g_ad_loss(fake_la_cam) #b2a\n","    g_ad_loss_gb_cam = g_ad_loss(fake_gb_cam) #a2b\n","    g_ad_loss_lb_cam = g_ad_loss(fake_lb_cam) #a2b\n","    g_ad_loss_cam_total = g_ad_loss_ga_cam + g_ad_loss_la_cam + g_ad_loss_gb_cam + g_ad_loss_lb_cam\n","\n","    g_cycle_loss_a = g_cycle_loss(x_aba, real_a) #both\n","    g_cycle_loss_b = g_cycle_loss(x_bab, real_b) #both\n","    g_cycle_loss_total = g_cycle_loss_a + g_cycle_loss_b\n","\n","    g_identify_loss_a = g_identify_loss(x_aa, real_a) #b2a\n","    g_identify_loss_b = g_identify_loss(x_bb, real_b) #a2b\n","    g_identify_loss_a_total = g_identify_loss_a + g_identify_loss_b\n","\n","    g_cam_loss_a = g_cam_loss(x_ba_cam, x_aa_cam) #b2a\n","    g_cam_loss_b = g_cam_loss(x_ab_cam, x_bb_cam) #a2b\n","    g_cam_loss_total = g_cam_loss_a + g_cam_loss_b\n","\n","    g_loss = (g_ad_loss_total + g_ad_loss_cam_total) + 10*g_cycle_loss_total + 10*g_identify_loss_a_total + 1000*g_cam_loss_total\n","\n","    g_loss.backward()\n","\n","    opt_g.step()\n","\n","    g_a2b.apply(rho_clipper)\n","    g_b2a.apply(rho_clipper)\n","\n","    return d_loss, g_loss"]},{"cell_type":"markdown","source":["## Preparation before starting training"],"metadata":{"id":"eznL1ehaoh5T"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Js0zo3K62fXl"},"outputs":[],"source":["# make directories in colab and drive for saving trained models\n","\n","saved_models_base_dir = 'saved_models'\n","!mkdir {saved_models_base_dir}\n","\n","saved_models_dirname = 'UGATIT_{}'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","saved_models_drive_path = f'{base_dir}/{saved_models_base_dir}/{saved_models_dirname}'\n","!mkdir {saved_models_drive_path}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2o_CnXhwppD"},"outputs":[],"source":["# display training logs on TensorBoard\n","\n","log_dir=\"runs/\"\n","\n","summary_writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVmYt8G3xHaK"},"outputs":[],"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","%load_ext tensorboard\n","%tensorboard --logdir {log_dir}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PA1Px5pLBOXs"},"outputs":[],"source":["# training schedule definition\n","\n","# number of epochs for this training\n","NUM_EPOCHS = 30\n","# number of epochs of pre-trained models\n","pre_trained_epoch = 260\n","\n","# do decay learning rate gradually from decay_start_epoch to end_epoch or not\n","RL_DECAY_MODE = True\n","# start decaying learning rates at this epoch (if RL_DECAY_MODE is False, not needed)\n","decay_start_epoch = 0\n","# at this epoch, the training is finished and learning rates reach zero (if RL_DECAY_MODE is False, not needed)\n","end_epoch = 300"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMWPSIKp_CUk"},"outputs":[],"source":["iter_per_epoch = min(len(train_a), len(train_b))\n","total_iter = NUM_EPOCHS * iter_per_epoch\n","if RL_DECAY_MODE:\n","    print(end_epoch - decay_start_epoch)\n","    total_decay_iter = (end_epoch - decay_start_epoch) * iter_per_epoch"]},{"cell_type":"code","source":["update_display_iter_rate = 250\n","save_models_epoch_rate = 30"],"metadata":{"id":"HicOIBoCKfVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBzHKYRF_jcv"},"outputs":[],"source":["def save_models_drive(epoch):\n","    save_dict = {}\n","    for model_name in ['g_a2b', 'g_b2a', 'd_ga', 'd_la', 'd_gb', 'd_lb']:\n","        save_dict[model_name] = globals()[model_name].state_dict()\n","    save_dict['opt_g'] = opt_g.state_dict()\n","    save_dict['opt_d'] = opt_d.state_dict()\n","\n","    if RL_DECAY_MODE:\n","        saved_models_filename = 'epoch-{}_d{}-{}'.format(epoch, decay_start_epoch, end_epoch)\n","    else:\n","        saved_models_filename = 'epoch-{}'.format(epoch)\n","    saved_models_path = os.path.join(saved_models_base_dir, f'{saved_models_filename}.pt')\n","\n","    torch.save(save_dict, saved_models_path)\n","\n","    os.system(f'cp {saved_models_path} {saved_models_drive_path}/{saved_models_filename}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYeidON_Bp9v"},"outputs":[],"source":["def log_train_info(epoch, n_data):\n","    print('{} / {} epochs'.format(epoch, NUM_EPOCHS))\n","    print('{} / {} steps per epoch'.format(n_data, iter_per_epoch))\n","    # print('{} total steps'.format(train_iter))\n","    print('Learning Rate: {}'.format(opt_g.param_groups[0]['lr']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMSAJ1MZQOuX"},"outputs":[],"source":["import gc\n","print(gc.collect())\n","\n","torch.cuda.empty_cache()\n","\n","!nvidia-smi"]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"Q9xRCeOB5CFd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtNa_Fdc9u1W"},"outputs":[],"source":["train_iter = 0\n","\n","if RL_DECAY_MODE:\n","    print('RL_DECAY_MODE is True!')\n","\n","for epoch in range(NUM_EPOCHS):\n","\n","    d_losses_per_epoch = []\n","    g_losses_per_epoch = []\n","\n","    for i_data, (real_a, real_b) in enumerate(zip(train_a, train_b)):\n","\n","        batch_size_a = real_a.shape[0]\n","        batch_size_b = real_b.shape[0]\n","        if (batch_size_a != batch_size_b):\n","            continue\n","\n","        if RL_DECAY_MODE and (epoch + 1 + pre_trained_epoch) > decay_start_epoch:\n","            opt_g.param_groups[0]['lr'] -= (adam_lr / total_decay_iter)\n","            opt_d.param_groups[0]['lr'] -= (adam_lr / total_decay_iter)\n","\n","        real_a = real_a.to(device)\n","        real_b = real_b.to(device)\n","\n","        d_loss, g_loss = train_step(real_a, real_b)\n","\n","        d_losses_per_epoch.append(d_loss.item())\n","        g_losses_per_epoch.append(g_loss.item())\n","\n","        if (train_iter % update_display_iter_rate == 0):\n","            d_mean_loss = np.mean(d_losses_per_epoch)\n","            g_mean_loss = np.mean(g_losses_per_epoch)\n","\n","            summary_writer.add_scalar('discriminator_loss', d_mean_loss, train_iter)\n","            summary_writer.add_scalar('generator_loss', g_mean_loss, train_iter)\n","\n","            d_losses_per_epoch = []\n","            g_losses_per_epoch = []\n","\n","            display.clear_output(wait=True)\n","\n","            log_train_info(epoch, i_data)\n","            generate_images(g_a2b, sample_a)\n","            generate_images(g_b2a, sample_b)\n","        \n","        train_iter += 1\n","        print('.', end='', flush=True)\n","\n","    if ((epoch + 1) % save_models_epoch_rate == 0 and (epoch + 1) < NUM_EPOCHS):\n","        save_models_drive(epoch + 1 + pre_trained_epoch)\n","\n","save_models_drive(NUM_EPOCHS + pre_trained_epoch)\n","\n","logs_filename = 'logs.zip'\n","os.system(f'zip -r {logs_filename} {log_dir}')\n","os.system(f'cp {logs_filename} {saved_models_drive_path}/{logs_filename}')"]},{"cell_type":"markdown","source":["## Check trained models"],"metadata":{"id":"Py31O89ALnR1"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KBiiV2maJzUm"},"outputs":[],"source":["# check with images used for training\n","\n","for n_data, (real_a, real_b) in enumerate(zip(train_a, train_b)):\n","    real_a = real_a.to(device)\n","    # real_b = real_b.to(device)\n","    generate_images(g_a2b, real_a)\n","    # generate_images(g_b2a, real_b)\n","    if (n_data > 10):\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyayKUUD-AAJ"},"outputs":[],"source":["# check with your images\n","\n","!mkdir myimg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a3ShI_-W9T_P"},"outputs":[],"source":["import glob\n","myimg_paths = []\n","for path in ['jpg', 'png', 'JPG', 'jpeg']:\n","    myimg_paths.extend(glob.glob(f'myimg/*.{path}'))\n","myimg_paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRNSLqNS-CD7"},"outputs":[],"source":["transformer_myimg = ImageModification(resize_pixel=256, min_scale=0.8)\n","\n","ds_myimg = GANDataset(file_list=myimg_paths, transform=transformer_myimg)\n","\n","myimgs = torch.utils.data.DataLoader(ds_myimg, batch_size=BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLfsU5_cw5wg"},"outputs":[],"source":["for n_data, myimg in enumerate(myimgs):\n","    myimg = myimg.to(device)\n","    generate_images(g_a2b, myimg)\n","    # if (n_data > 10):\n","    #     break"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"ugatit_train_example.ipynb","provenance":[],"authorship_tag":"ABX9TyOOWEltVbl2duT2eJq5QbVr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}